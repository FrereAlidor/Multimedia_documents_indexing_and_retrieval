{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acde13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319e9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acces_fichier(chemin):\n",
    "    fichier = open(chemin, encoding=\"utf8\")\n",
    "    contenu = fichier.read()\n",
    "    fichier.close()\n",
    "    return contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b2b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoup (chaine):\n",
    "    return chaine.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524530cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23468\n",
      "['\\n\\n', '', '\\n', 'Reprise', 'de', 'la', 'session\\n', 'Je', 'déclare', 'reprise', 'session', 'du', 'Parlement', 'européen', 'qui', 'avait', 'été', 'interrompue', 'le', 'vendredi', '17', 'décembre', 'dernier', 'et', 'je', 'vous', 'renouvelle', 'tous', 'mes', 'vux', 'en', 'espérant', 'que', 'avez', 'passé', 'bonnes', 'vacances.\\n', 'Comme', 'pu', 'constater,', 'grand', '\"bogue', \"l'an\", '2000\"', 'ne', \"s'est\", 'pas', 'produit.\\n', 'En', 'revanche,', 'les', 'citoyens', \"d'un\", 'certain', 'nombre', 'nos', 'pays', 'ont', 'victimes', 'catastrophes', 'naturelles', 'vraiment', 'terribles.\\n', 'Vous', 'souhaité', 'un', 'débat', 'à', 'ce', 'sujet', 'dans', 'prochains', 'jours,', 'au', 'cours', 'cette', 'période', 'session.\\n', 'attendant,', 'souhaiterais,', 'comme', 'collègues', 'me', \"l'ont\", 'demandé,', 'nous', 'observions', 'une', 'minute', 'silence', 'pour', 'toutes', 'victimes,', 'des', 'tempêtes', 'notamment,', 'différents', \"l'Union\", 'européenne', 'touchés.\\n', 'invite', 'lever', 'silence.\\n', '(Le', 'Parlement,', 'debout,', 'observe', 'silence)\\n', 'Madame', 'Présidente,', \"c'est\", 'motion', 'procédure.\\n', 'probablement', 'appris', 'par', 'presse', 'télévision', 'plusieurs', 'attentats', 'bombe', 'crimes', 'perpétrés', 'Sri', 'Lanka.\\n', \"L'une\", 'personnes', 'vient', \"d'être\", 'assassinée', 'Lanka', 'est', 'M.', 'Kumar', 'Ponnambalam,', 'rendu', 'visite', 'il', 'y', 'a', 'quelques', 'mois', 'peine.\\n', 'Ne', 'pensez-vous', 'pas,', \"qu'il\", 'conviendrait', \"d'écrire\", 'lettre', 'président', 'lui', 'communiquer', 'déplore', 'morts', 'violentes,', 'dont', 'celle', \"l'inviter\", 'instamment', 'faire', 'tout', 'son', 'pouvoir', 'chercher', 'réconciliation', 'pacifique', 'mettre', 'terme', 'situation', 'particulièrement', 'difficile.\\n', 'Oui,', 'Monsieur', 'Evans,', 'pense', \"qu'une\", 'initiative', 'sens', 'venez', 'suggérer', 'serait', 'fait', 'appropriée.\\n', 'Si', \"l'Assemblée\", \"d'accord,\", 'ferai', 'Evans', \"l'a\", 'suggéré.\\n', 'voudrais', 'demander', 'conseil', \"l'article\", '143,', 'concerne', \"l'irrecevabilité.\\n\", 'Ma', 'question', 'porte', 'sur', \"l'ordre\", 'jour', 'jeudi', 'soulèverai', 'donc', 'nouvelle', 'fois.\\n', 'Le', 'paragraphe', '6', 'rapport', 'Cunha', 'programmes', \"d'orientation\", 'pluriannuels,', 'sera', 'soumis', 'jeudi,', 'propose', \"d'introduire\", 'sanctions', 'applicables', 'aux', 'respectent', 'objectifs', 'annuels', 'réduction', 'leur', 'flotte.\\n', 'Il', 'précise', 'cela', 'devrait', 'être', 'malgré', 'principe', 'stabilité', 'relative.\\n', 'À', 'mon', 'sens,', 'relative', 'juridique', 'fondamental', 'politique', 'commune', 'pêche', 'toute', 'proposition', 'bouleversant', 'juridiquement', 'irrecevable.\\n', 'savoir', 'si', \"l'on\", 'peut', 'avancer', 'objection', 'type', \"n'est\", \"qu'un\", 'rapport,', 'législative,', 'suis', 'habilité', 'jeudi.\\n', \"C'est\", 'exactement', 'moment-là', 'pourrez,', 'effet,', 'souhaitez,', 'soulever', 'question,', \"c'est-à-dire\", 'avant', 'début', 'présentation', 'rapport.\\n', 'alors', 'se', 'déroule', 'première', \"l'année\", 'européen,', \"l'exécution\", 'condamné', 'mort', 'Texas', 'États-Unis,', 'jeune', 'homme', '34', 'ans', 'appelé', 'Hicks,', 'fixée,', 'malheureusement,']\n"
     ]
    }
   ],
   "source": [
    "index = {}\n",
    "for chemin in glob.glob(\"D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr/*\")[:5]:\n",
    "    chaine = acces_fichier(chemin)\n",
    "    \n",
    "    mots = decoup(chaine)\n",
    "    for mot in mots:\n",
    "        if mot not in index:\n",
    "            index[mot] = set()  \n",
    "        index[mot].add(chemin)\n",
    "\n",
    "print(len(index ))# t a i l l e\n",
    "print(list(index.keys ())[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d800f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-21-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-20-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-17-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-18-fr.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(index[\"indique\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa7c6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-20-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-17-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-18-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-21-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-19-fr.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(index[\"européenne\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1a796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-18-fr.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(index[\"toto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f025e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {mot:list( liste_fichiers )\n",
    "for mot , liste_fichiers in index.items ()}\n",
    "w = open(\"index.json\", \"w\")\n",
    "w.write(json.dumps(index ))\n",
    "w.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcefdb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Commission', 'Europeenne']\n"
     ]
    }
   ],
   "source": [
    "comEur=\"Commission Europeenne\"\n",
    "nv=decoup(comEur)\n",
    "\n",
    "print(nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d462ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-20-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-17-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-18-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-21-fr.txt', 'D:/Indexation/SHARED_M2SIM_Indexation/TP/europarl/fr\\\\ep-00-01-19-fr.txt']\n"
     ]
    }
   ],
   "source": [
    "print(index[nv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15afe727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_contextes (chaine , terme , taille_contexte = 30):\n",
    "    match = re. search (terme , chaine )\n",
    "    contexts = []\n",
    "    while match is not None:\n",
    "#Les b o r n e s g a u c h e e t d r o i t e a u t o u r du mot :\n",
    "        gauche = max(match.start()-taille_contexte -1, 0)\n",
    "        droite = match.end ()+1+ taille_contexte\n",
    "        contexts . append ( chaine [ gauche : droite ])\n",
    "        chaine = chaine [match.end ():]\n",
    "        match = re.search(terme , chaine )\n",
    "    for c in contexts :\n",
    "        print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a979b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1713415706.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [13]\u001b[1;36m\u001b[0m\n\u001b[1;33m    while open(resultat,'r') as f:\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for resutat in list:\n",
    "    while open(resultat,'r') as f:\n",
    "        chaine=f.resd()\n",
    "        terme=\"commission eurpéene\"\n",
    "        content=afficher_contextes(chaine,terme)\n",
    "        print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "379cbeed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texte' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_stopwords_list = stopwords.words('english') + stopwords.words('french')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(\u001b[43mtexte\u001b[49m, language \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrench\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(stopwords.words('french'))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrench\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texte' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# final_stopwords_list = stopwords.words('english') + stopwords.words('french')\n",
    "tokens = nltk.word_tokenize(texte, language ='french')\n",
    "# print(stopwords.words('french'))\n",
    "tokens = [w for w in tokens if w not in stopwords.words('french')]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0750681",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = creer_index ()\n",
    "index_inverse = creer_index_inverse ()\n",
    "print (\" Nombre de termes diff«erents : \", len(index.keys ()))\n",
    "print (\" Nombre de documents :\", len( index_inverse .keys ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dac7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "requete = \"les travaux indexés\"\n",
    "docs_trouves = requeter_documets (requete , index)\n",
    "print (\" Nombre de documents trouvees :\", len( docs_trouves ))\n",
    "requete = \" sensibilisation minorit «es\"\n",
    "docs_trouves = requeter_documets (requete , index)\n",
    "print (\" Nombre de documents trouv «ees :\", len( docs_trouves ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allDocs ={ \"docA\":{\"Le\":0.25 ,\"petit\":0.25 ,\"chat\":0.25 ,\"dort\" :0.25},\n",
    "\"docB\": {\"Le\":0.3333 , \"chat\":0.3333 , \"dort\" :0.3333},\n",
    "\"docC\": {\"Jean\":0.5 , \"dort\" :0.5}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2948a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c492edf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allDocs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mallDocs\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'allDocs' is not defined"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(allDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d668bf6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa77ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docA='Le petit chat dort'\n",
    "docB='Le chat dort'\n",
    "docC='Jean dort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81222996",
   "metadata": {},
   "outputs": [],
   "source": [
    "phraseA=docA.split(' ')\n",
    "phraseB=docB.split(' ')\n",
    "phraseC=docC.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7876f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i', 'd', 'o', 'r', 't', 'c', 'a', 'h', 'p', 'L', ' ', 'e'}\n"
     ]
    }
   ],
   "source": [
    "uniqueWords = set(docA).union(set(docB))\n",
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecffaa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of pi is approximately 3.142.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(f'The value of pi is approximately {math.pi:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "158c7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mame_Khalifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adef60aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c04791f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m table \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.25\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpetit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.25\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.25\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdort\u001b[39m\u001b[38;5;124m\"\u001b[39m :\u001b[38;5;241m0.25\u001b[39m}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, phone \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num' is not defined"
     ]
    }
   ],
   "source": [
    " table = {\"Le\":0.25 ,\"petit\":0.25 ,\"chat\":0.25 ,\"dort\" :0.25}\n",
    ">>> for name, phone in table.items():\n",
    "...     print(f'{name:10} ==> {num:10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231c981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
